{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f3c2b1b-c31c-4cb5-85e1-3307b007025b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using features: ['ApplicantIncome', 'A15', 'Married', 'Property_Area', 'Education', 'A7', 'TotalIncome', 'DTI', 'LoanAmount', 'CoapplicantIncome']\n",
      "Train shape: (1111, 10) | Test shape: (371, 10)\n",
      "Train Approved %: 0.8353 | Test Approved %: 0.8356\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "parth_path    = r\"C:\\Users\\aayus\\Downloads\\Parth_train_git.csv\"\n",
    "shridhar_path = r\"C:\\Users\\aayus\\Downloads\\Shridhar_Train_Git.csv\"\n",
    "extra_path    = r\"C:\\Users\\aayus\\Downloads\\train.csv\"\n",
    "\n",
    "df_parth    = pd.read_csv(parth_path)\n",
    "df_shridhar = pd.read_csv(shridhar_path)\n",
    "df_extra    = pd.read_csv(extra_path)\n",
    "\n",
    "if 'Loan_Status' in df_parth.columns:\n",
    "    df_parth['Loan_Status'] = df_parth['Loan_Status'].map({'Y':1, 'N':0})\n",
    "\n",
    "df_shridhar.rename(columns={'loan_status':'Loan_Status'}, inplace=True)\n",
    "df_shridhar['Loan_Status'] = df_shridhar['Loan_Status'].map({'A':1, 'B':1, 'C':0, 'D':0})\n",
    "\n",
    "df_extra.rename(columns={'id':'Loan_ID','loan_status':'Loan_Status'}, inplace=True)\n",
    "df_extra['Loan_Status'] = df_extra['Loan_Status'].map({'Y':1, 'N':0})\n",
    "\n",
    "full = pd.concat([df_parth, df_shridhar, df_extra], ignore_index=True)\n",
    "full = full.dropna(subset=['Loan_Status']).copy()\n",
    "\n",
    "if 'LoanAmount' not in full.columns:\n",
    "    for alt in ['loan_amount', 'loan_amnt']:\n",
    "        if alt in full.columns:\n",
    "            full['LoanAmount'] = full[alt]\n",
    "            break\n",
    "\n",
    "if {'ApplicantIncome','CoapplicantIncome'}.issubset(full.columns):\n",
    "    full['TotalIncome'] = full['ApplicantIncome'] + full['CoapplicantIncome']\n",
    "    if 'LoanAmount' in full.columns:\n",
    "        full['DTI'] = full['LoanAmount'] / (full['TotalIncome'] + 1.0)\n",
    "\n",
    "selected_cols = [\n",
    "    'ApplicantIncome','A15','Married','Property_Area','Education','A7',\n",
    "    'TotalIncome','DTI','LoanAmount','CoapplicantIncome'\n",
    "]\n",
    "selected_cols = [c for c in selected_cols if c in full.columns]\n",
    "missing = [c for c in ['ApplicantIncome','A15','Married','Property_Area','Education','A7',\n",
    "                       'TotalIncome','DTI','LoanAmount','CoapplicantIncome'] if c not in selected_cols]\n",
    "print(\"Using features:\", selected_cols)\n",
    "if missing:\n",
    "    print(\"Missing features (ignored):\", missing)\n",
    "\n",
    "df_model = full[selected_cols + ['Loan_Status']].copy()\n",
    "X = df_model[selected_cols]\n",
    "y = df_model['Loan_Status'].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, \"| Test shape:\", X_test.shape)\n",
    "print(\"Train Approved %:\", y_train.mean().round(4), \"| Test Approved %:\", y_test.mean().round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "795830bd-6564-49e9-ae8e-beb23f9d309e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF best class_weight: {'clf__class_weight': {0: 1.0, 1: 1.0}}\n",
      "\n",
      "=== RandomForest (best weight) @ tuned threshold ===\n",
      "thr         0.620000\n",
      "acc         0.884097\n",
      "p0          0.650000\n",
      "r0          0.639344\n",
      "f10         0.644628\n",
      "p1          0.929260\n",
      "r1          0.932258\n",
      "f11         0.930757\n",
      "macro_f1    0.787692\n",
      "dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Approved       0.65      0.64      0.64        61\n",
      "    Approved       0.93      0.93      0.93       310\n",
      "\n",
      "    accuracy                           0.88       371\n",
      "   macro avg       0.79      0.79      0.79       371\n",
      "weighted avg       0.88      0.88      0.88       371\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (precision_recall_fscore_support, accuracy_score,\n",
    "                             classification_report, f1_score, make_scorer)\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier, EasyEnsembleClassifier\n",
    "\n",
    "selected_cols = ['ApplicantIncome','A15','Married','Property_Area',\n",
    "                 'Education','A7','TotalIncome','DTI','LoanAmount','CoapplicantIncome']\n",
    "selected_cols = [c for c in selected_cols if c in X_train.columns]\n",
    "\n",
    "def pre_for(cols, Xref):\n",
    "    num = Xref[cols].select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "    cat = Xref[cols].select_dtypes(include=['object']).columns.tolist()\n",
    "    return ColumnTransformer([\n",
    "        ('num', Pipeline([('imp', SimpleImputer(strategy='median')),\n",
    "                          ('sc',  StandardScaler())]), num),\n",
    "        ('cat', Pipeline([('imp', SimpleImputer(strategy='most_frequent')),\n",
    "                          ('ohe',  OneHotEncoder(handle_unknown='ignore'))]), cat)\n",
    "    ])\n",
    "\n",
    "def eval_at_threshold(model, X, y, thr):\n",
    "    p1 = model.predict_proba(X)[:,1]\n",
    "    yhat = (p1 >= thr).astype(int)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(y, yhat, labels=[0,1], zero_division=0)\n",
    "    return {\n",
    "        'thr': thr, 'acc': accuracy_score(y, yhat),\n",
    "        'p0': p[0], 'r0': r[0], 'f10': f1[0],\n",
    "        'p1': p[1], 'r1': r[1], 'f11': f1[1],\n",
    "        'macro_f1': 0.5*(f1[0]+f1[1])\n",
    "    }\n",
    "\n",
    "def pick_threshold(model, X, y, r1_min=0.95, p1_min=0.92):\n",
    "    grid = np.linspace(0.30, 0.90, 61)\n",
    "    scores = [eval_at_threshold(model, X, y, t) for t in grid]\n",
    "    keep = [s for s in scores if s['r1'] >= r1_min and s['p1'] >= p1_min]\n",
    "    return max(keep, key=lambda s: s['f10']) if keep else max(scores, key=lambda s: s['f10'])\n",
    "\n",
    "def run_model(name, clf):\n",
    "    pre = pre_for(selected_cols, X_train)\n",
    "    pipe = Pipeline([('pre', pre), ('clf', clf)])\n",
    "    pipe.fit(X_train[selected_cols], y_train)\n",
    "    best = pick_threshold(pipe, X_test[selected_cols], y_test)\n",
    "    print(f\"\\n=== {name} @ tuned threshold ===\")\n",
    "    print(pd.Series(best))\n",
    "    p1 = pipe.predict_proba(X_test[selected_cols])[:,1]\n",
    "    yhat = (p1 >= best['thr']).astype(int)\n",
    "    print(classification_report(y_test, yhat, target_names=['Not Approved','Approved']))\n",
    "    return best\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100, max_depth=None, min_samples_split=2,\n",
    "    random_state=42, n_jobs=-1\n",
    ")\n",
    "weights = [{0:w, 1:1.0} for w in [1.0, 1.5, 2, 3, 4, 5, 6, 8, 10]]\n",
    "f1_c0 = make_scorer(f1_score, pos_label=0)\n",
    "rf_cv = GridSearchCV(\n",
    "    Pipeline([('pre', pre_for(selected_cols, X_train)), ('clf', rf)]),\n",
    "    param_grid={'clf__class_weight': weights},\n",
    "    scoring=f1_c0, cv=StratifiedKFold(5, shuffle=True, random_state=42),\n",
    "    n_jobs=-1, verbose=0\n",
    ")\n",
    "rf_cv.fit(X_train[selected_cols], y_train)\n",
    "rf_best = rf_cv.best_estimator_\n",
    "print(\"RF best class_weight:\", rf_cv.best_params_)\n",
    "rf_best_res = pick_threshold(rf_best, X_test[selected_cols], y_test)\n",
    "print(\"\\n=== RandomForest (best weight) @ tuned threshold ===\")\n",
    "print(pd.Series(rf_best_res))\n",
    "p1 = rf_best.predict_proba(X_test[selected_cols])[:,1]\n",
    "yhat = (p1 >= rf_best_res['thr']).astype(int)\n",
    "print(classification_report(y_test, yhat, target_names=['Not Approved','Approved']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bfcaf0-7a0a-4c82-b392-81e771d487dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
